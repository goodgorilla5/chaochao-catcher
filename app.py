import streamlit as st
import pandas as pd
import re
import requests
import concurrent.futures

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº«", layout="wide")

# è¾²æœƒå®šç¾©
FARMER_MAP = {"ç‡•å·¢": "S00076", "å¤§ç¤¾": "S00250", "é˜¿è“®": "S00098"}

try:
    GITHUB_TOKEN = st.secrets["github_token"]
except:
    st.error("âŒ è«‹è¨­å®š github_token")
    st.stop()

def deep_parse(content):
    # æ”¹ç”¨æµæ°´è™Ÿé—œéµå­— [AT]11... ä½œç‚ºçµ•å°åˆ†å‰²é»ï¼Œé¿å…è³‡æ–™ç²˜é€£
    records = re.split(r'(?=[AT]\d{10,})', content)
    rows = []
    grade_map = {"1": "ç‰¹", "2": "å„ª", "3": "è‰¯"}
    
    for rec in records:
        if not rec.strip(): continue
        try:
            # 1. å°‹æ‰¾æ ¸å¿ƒéŒ¨é» (æ—¥æœŸ+ç­‰ç´š+S00)
            m = re.search(r'(\d{8})\s+(\d{2})(S00\d{6})', rec)
            if not m: continue
            
            raw_date = m.group(1)
            level_code = m.group(2)[0]
            market_anchor = m.group(3)
            
            # 2. æå–æµæ°´è™Ÿ (æ¯ç­†è¨˜éŒ„çš„æœ€é–‹é ­)
            serial = rec[:m.start()].strip().replace(" ", "")

            # 3. æ•¸æ“šæ®µç²¾ç¢ºè§£æ
            # ç¯„ä¾‹ï¼š002+00012+02300+000002760+6000+4304
            data_part = rec[m.end():]
            if '+' not in data_part: continue
            
            parts = data_part.split('+')
            if len(parts) < 4: continue

            # é—œéµï¼šå–®åƒ¹èˆ‡ç¸½åƒ¹å»æ‰ç³»çµ±æœ«ä½ 0
            pieces = int(parts[0][-3:].strip())
            weight = int(parts[1].strip())
            
            # å–®åƒ¹ä¿®æ­£ï¼šä¾‹å¦‚ 02300 -> 230
            p_str = parts[2].strip().split()[0]
            price = int(p_str[:-1]) if p_str else 0
            
            # ç¸½åƒ¹ä¿®æ­£
            t_str = parts[3].strip().split()[0]
            total = int(t_str[:-1]) if t_str else 0
            
            # è²·å®¶ä¿®æ­£ï¼šå–æœ€å¾Œä¸€æ®µ + è™Ÿå¾Œçš„æ•¸å­—ï¼Œä¸¦åš´æ ¼é™åˆ¶ 4 ç¢¼é¿å…åƒåˆ°ä¸‹ä¸€ç­†
            buyer_raw = parts[-1].strip()
            buyer_match = re.search(r'^\d+', buyer_raw)
            buyer = buyer_match.group() if buyer_match else ""

            # å“ç¨®æœå°‹
            v_match = re.search(r'(F22|FP1|FP2|FP3|FP5|FI3)', parts[0])
            variety = v_match.group(1) if v_match else "F22"

            # åˆ¤å®šè¾²æœƒ
            farm = "å…¶ä»–"
            for name, code in FARMER_MAP.items():
                if code in market_anchor: farm = name; break
            if farm == "å…¶ä»–": continue

            rows.append({
                "è¾²æœƒ": farm, 
                "æ—¥æœŸ": f"{raw_date[:3]}/{raw_date[3:5]}/{raw_date[5:7]}",
                "ç­‰ç´š": grade_map.get(level_code, level_code), 
                "å°ä»£": market_anchor[6:9],
                "ä»¶æ•¸": pieces, "å…¬æ–¤": weight, "å–®åƒ¹": price, "ç¸½åƒ¹": total,
                "è²·å®¶": buyer, "æµæ°´è™Ÿ": serial, "å“ç¨®": variety, "raw_date": raw_date[:7]
            })
        except: continue
    return rows

@st.cache_data(ttl=60)
def fetch_data():
    all_rows = []
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    try:
        r = requests.get("https://api.github.com/repos/goodgorilla5/chaochao-catcher/contents/", headers=headers)
        files = [f for f in r.json() if f['name'].lower().endswith('.scp')]
        for f_info in files:
            res = requests.get(f_info['download_url'], headers=headers)
            all_rows.extend(deep_parse(res.content.decode("big5", errors="ignore")))
        df = pd.DataFrame(all_rows)
        if not df.empty:
            # æ’é™¤é‡è¤‡ä¸¦æŒ‰å–®åƒ¹æ’åº
            df = df.drop_duplicates(subset=["æµæ°´è™Ÿ", "å°ä»£", "å–®åƒ¹", "è²·å®¶"])
            return df.sort_values(["raw_date", "å–®åƒ¹"], ascending=[False, False])
    except: pass
    return pd.DataFrame()

# --- ä¸»ä»‹é¢ ---
st.title("ğŸ è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº«")
df = fetch_data()

if not df.empty:
    st.sidebar.header("ğŸ¨ é¡¯ç¤ºè¨­å®š")
    show_serial = st.sidebar.checkbox("é¡¯ç¤ºæµæ°´è™Ÿ", value=False)
    
    target_farm = st.selectbox("ğŸ¥ é¸æ“‡è¾²æœƒ", list(FARMER_MAP.keys()))
    f_df = df[df['è¾²æœƒ'] == target_farm].copy()
    
    v_list = sorted(f_df['å“ç¨®'].unique())
    target_v = st.selectbox("ğŸ é¸æ“‡å“ç¨®", v_list, index=v_list.index("F22") if "F22" in v_list else 0)
    f_df = f_df[f_df['å“ç¨®'] == target_v]

    dates = sorted(f_df['raw_date'].unique(), reverse=True)
    sel_date = st.selectbox("ğŸ“… é¸æ“‡æ—¥æœŸ", dates)
    
    # æœå°‹æ¡†ï¼šå°ä»£èˆ‡è²·å®¶åˆ†é–‹
    sc1, sc2 = st.columns(2)
    with sc1: s_sub = st.text_input("ğŸ” æœå°‹å°ä»£")
    with sc2: s_buy = st.text_input("ğŸ‘¤ æœå°‹è²·å®¶")

    final_df = f_df[f_df['raw_date'] == sel_date]
    if s_sub: final_df = final_df[final_df['å°ä»£'].str.contains(s_sub)]
    if s_buy: final_df = final_df[final_df['è²·å®¶'].str.contains(s_buy)]

    # è¡¨æ ¼é¡¯ç¤º (è²·å®¶å·²ä¿®æ­£)
    cols = ["æ—¥æœŸ", "ç­‰ç´š", "å°ä»£", "ä»¶æ•¸", "å…¬æ–¤", "å–®åƒ¹", "è²·å®¶"]
    if show_serial: cols.insert(0, "æµæ°´è™Ÿ")
    st.dataframe(final_df[cols], use_container_width=True, height=450, hide_index=True)

    # --- çµ±è¨ˆæ‘˜è¦å€ ---
    st.divider()
    if not final_df.empty:
        t_pcs, t_kg, t_val = final_df['ä»¶æ•¸'].sum(), final_df['å…¬æ–¤'].sum(), final_df['ç¸½åƒ¹'].sum()
        avg_p = t_val / t_kg if t_kg > 0 else 0
        st.markdown(f"##### ğŸ“‰ {target_farm} ({target_v}) æ•¸æ“šæ‘˜è¦")
        m_cols = st.columns(6)
        metrics = [
            ("ç¸½ä»¶æ•¸", f"{int(t_pcs)} ä»¶"), ("ç¸½å…¬æ–¤", f"{int(t_kg)} kg"),
            ("æœ€é«˜åƒ¹", f"{final_df['å–®åƒ¹'].max()} å…ƒ"), ("æœ€ä½åƒ¹", f"{final_df['å–®åƒ¹'].min()} å…ƒ"),
            ("å¹³å‡å–®åƒ¹", f"{avg_p:.1f} å…ƒ"), ("å€é–“ç¸½åƒ¹", f"{int(t_val):,} å…ƒ")
        ]
        for i, (l, v) in enumerate(metrics):
            with m_cols[i]:
                st.markdown(f'<div style="background-color:#f0f2f6;padding:10px;border-radius:5px;text-align:center;">'
                            f'<p style="margin:0;font-size:12px;color:#555;">{l}</p>'
                            f'<p style="margin:0;font-size:16px;font-weight:bold;color:#111;">{v}</p></div>', unsafe_allow_html=True)
else:
    st.warning("ğŸ˜­ è®€å–å¤±æ•—ï¼Œè«‹ç¢ºèªè³‡æ–™æºã€‚")