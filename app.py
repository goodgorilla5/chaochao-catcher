import streamlit as st
import pandas as pd
import re
import requests
import concurrent.futures

st.set_page_config(page_title="è¾²æœƒè¡Œæƒ…çµ‚æ¥µç‰ˆ", layout="wide")

# è¾²æœƒå®šç¾©
FARMER_MAP = {"ç‡•å·¢": "S00076", "å¤§ç¤¾": "S00250", "é˜¿è“®": "S00098", "é«˜æ¨¹": "T00493"}

try:
    GITHUB_TOKEN = st.secrets["github_token"]
except:
    st.error("âŒ è«‹è¨­å®š github_token")
    st.stop()

def deep_parse(content):
    rows = []
    # é›·é”æƒæè¦å¾‹ï¼š[8ç¢¼æ—¥æœŸ][ä»»æ„ç©ºç™½][2ç¢¼ç­‰ç´š][S00æˆ–T00][å¸‚å ´+å°ä»£ 6ç¢¼]
    # ä¾‹å¦‚ï¼š11502111  11S00250
    pattern = re.compile(r'(\d{8})\s+(\d{2})([S|T]00\d{6})')
    
    # æ‰¾å‡ºæ‰€æœ‰ç¬¦åˆè¦å¾‹çš„èµ·é»
    matches = list(pattern.finditer(content))
    
    for i in range(len(matches)):
        try:
            m = matches[i]
            raw_date = m.group(1)   # 11502111
            level_code = m.group(2) # 11, 21, 31
            anchor = m.group(3)     # S00250516
            
            # 1. å®šä½èˆ‡æµæ°´è™Ÿ
            start_pos = m.start()
            # æµæ°´è™Ÿæ˜¯é€™ç­†è³‡æ–™èµ·é»åˆ°å‰ä¸€ç­†è³‡æ–™çµ‚é»ä¹‹é–“çš„æ±è¥¿
            prev_end = matches[i-1].end() if i > 0 else 0
            # å¾€å‰æ‰¾ï¼Œå¦‚æœä¸­é–“æœ‰ '+' è™Ÿï¼Œä»£è¡¨é‚£æ˜¯ä¸Šä¸€ç­†çš„æ•¸æ“šï¼Œè¦é¿é–‹
            last_plus = content.rfind('+', prev_end, start_pos)
            search_from = last_plus + 30 if last_plus != -1 else prev_end
            serial = content[search_from:start_pos].strip().replace(" ", "")

            # 2. æ•¸æ“šæ®µï¼šå¾éŒ¨é»å¾Œæ‰¾ç¬¬ä¸€å€‹ '+' é–‹å§‹
            data_area = content[m.end():m.end()+150]
            if '+' not in data_area: continue
            
            # å“ç¨® (éŒ¨é»å¾Œåˆ°ç¬¬ä¸€å€‹ + è™Ÿ)
            variety = data_area.split('+')[0].strip()[:3]
            if variety not in ["F22", "FP1", "FP2", "FP3", "FP5", "FI3"]: continue

            # æ•¸å€¼
            parts = data_area.split('+')
            pieces = int(parts[0][-3:].strip())
            weight = int(parts[1].strip())
            price = int(parts[2].strip()[:4]) # å–å‰4ç¢¼ä¸¦è½‰æ•´æ•¸ (è‡ªå‹•å»æ‰æœ€å¾Œçš„0)
            total = int(parts[3].strip().split()[0])
            buyer = parts[-1].strip()[:4]

            # 3. åˆ¤å®šè¾²æœƒ
            farm = "å…¶ä»–"
            for name, code in FARMER_MAP.items():
                if code in anchor:
                    farm = name
                    break

            rows.append({
                "è¾²æœƒ": farm, "æ—¥æœŸ": f"{raw_date[:3]}/{raw_date[3:5]}/{raw_date[5:7]}",
                "ç­‰ç´š": {"1":"ç‰¹","2":"å„ª","3":"è‰¯"}.get(level_code[0], level_code),
                "å°ä»£": anchor[6:9], "å“ç¨®": variety, "ä»¶æ•¸": pieces,
                "å…¬æ–¤": weight, "å–®åƒ¹": price, "ç¸½åƒ¹": total, "è²·å®¶": buyer,
                "æµæ°´è™Ÿ": serial, "raw_date": raw_date[:7]
            })
        except: continue
    return rows

@st.cache_data(ttl=60)
def fetch_github_data():
    all_rows = []
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    try:
        r = requests.get("https://api.github.com/repos/goodgorilla5/chaochao-catcher/contents/", headers=headers)
        for f in r.json():
            if f['name'].lower().endswith('.scp'):
                res = requests.get(f['download_url'], headers=headers)
                all_rows.extend(deep_parse(res.content.decode("big5", errors="ignore")))
        return pd.DataFrame(all_rows)
    except: return pd.DataFrame()

# --- ä¸»ä»‹é¢ ---
st.title("ğŸ è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº« (å…¨è‡ªå‹•æ ¡æº–ç‰ˆ)")
df = fetch_github_data()

if not df.empty:
    farm_list = ["ç‡•å·¢", "å¤§ç¤¾", "é˜¿è“®", "é«˜æ¨¹"]
    target_farm = st.selectbox("ğŸ¥ é¸æ“‡è¾²æœƒ", farm_list)
    
    # ç¯©é¸å“ç¨® (é è¨­ F22 èœœæ£—)
    f_df = df[df['è¾²æœƒ'] == target_farm].copy()
    v_list = sorted(f_df['å“ç¨®'].unique())
    target_v = st.selectbox("ğŸ é¸æ“‡å“ç¨®", v_list, index=v_list.index("F22") if "F22" in v_list else 0)
    
    f_df = f_df[f_df['å“ç¨®'] == target_v]
    
    # æ—¥æœŸèˆ‡æœå°‹
    dates = sorted(f_df['raw_date'].unique(), reverse=True)
    sel_date = st.selectbox("ğŸ“… æ—¥æœŸ", dates)
    search = st.text_input("ğŸ” æœå°‹å°ä»£/è²·å®¶")
    
    final_df = f_df[f_df['raw_date'] == sel_date]
    if search:
        final_df = final_df[final_df['å°ä»£'].str.contains(search) | final_df['è²·å®¶'].str.contains(search)]

    st.dataframe(final_df[["æ—¥æœŸ", "ç­‰ç´š", "å°ä»£", "ä»¶æ•¸", "å…¬æ–¤", "å–®åƒ¹", "è²·å®¶", "æµæ°´è™Ÿ"]], use_container_width=True, hide_index=True)
    
    # çµ±è¨ˆæ‘˜è¦
    st.divider()
    c1, c2, c3 = st.columns(3)
    c1.metric("ç¸½å…¬æ–¤", f"{int(final_df['å…¬æ–¤'].sum())} kg")
    c2.metric("æœ€é«˜å–®åƒ¹", f"{final_df['å–®åƒ¹'].max()} å…ƒ")
    c3.metric("ç¸½é‡‘é¡", f"{int(final_df['ç¸½åƒ¹'].sum()):,} å…ƒ")
else:
    st.warning("ğŸ˜­ å€‰åº«ä¸­ç„¡æœ‰æ•ˆè³‡æ–™æˆ–è§£æå¤±æ•—ã€‚")