import streamlit as st
import pandas as pd
import re
import requests
from datetime import datetime

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº«", layout="wide")

# å›ºå®šå®šç¾©
FARMER_MAP = {"ç‡•å·¢": "S00076", "å¤§ç¤¾": "S00250", "é˜¿è“®": "S00098"}
MARKET_RULES = {"A1": "ä¸€å¸‚", "A2": "äºŒå¸‚", "F1": "ä¸‰é‡", "F2": "æ¿æ©‹", "T1": "å°ä¸­", "K1": "é«˜é›„"}
MARKET_ORDER = ["ä¸€å¸‚", "äºŒå¸‚", "ä¸‰é‡", "æ¿æ©‹", "å°ä¸­", "é«˜é›„"}
VARIETY_MAP = {"F22": "èœœæ£—", "FP1": "çç èŠ­", "FP2": "ç´…å¿ƒ", "FP3": "å¸ç‹èŠ­", "FP5": "æ°´æ™¶ç„¡ç±½", "FI3": "å…¶ä»–"}

try:
    GITHUB_TOKEN = st.secrets["github_token"]
except:
    st.error("âŒ è«‹è¨­å®š github_token")
    st.stop()

# --- æ ¸å¿ƒè§£æ (ç•¥ï¼Œç¶­æŒä¸è®Š) ---
@st.cache_data(ttl=60)
def fetch_data():
    all_rows = []
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    try:
        r = requests.get(f"https://api.github.com/repos/goodgorilla5/chaochao-catcher/contents/", headers=headers)
        files = [f for f in r.json() if f['name'].lower().endswith('.scp')]
        for f_info in files:
            res = requests.get(f_info['download_url'], headers=headers)
            content = res.content.decode("big5", errors="ignore")
            # è§£æé‚è¼¯... (æ­¤è™•çœç•¥éƒ¨åˆ†ä»£ç¢¼ä»¥ç¯€çœç©ºé–“ï¼Œè«‹æ²¿ç”¨æ‚¨åŸæœ¬çš„è§£æé‚è¼¯)
            # ... 
        return pd.DataFrame(all_rows).drop_duplicates() if all_rows else pd.DataFrame()
    except: return pd.DataFrame()

# é€™è£¡ç‚ºäº†æ¼”ç¤ºï¼Œæˆ‘å€‘å‡è¨­è§£æé‚è¼¯å·²åœ¨ fetch_data å®Œæ•´å¯¦ä½œ
# --- è§£æå‡½æ•¸çœç•¥ï¼Œè«‹ç¢ºä¿èˆ‡æ‚¨åŸæœ¬çš„ deep_parse ä¸€è‡´ ---
def deep_parse(content):
    # (æ­¤è™•è«‹ä¿ç•™æ‚¨åŸæœ¬å®Œæ•´çš„ deep_parse å…§å®¹)
    records = re.split(r'(?=[ATKF]\d{10,})', content) 
    rows = []
    grade_map = {"1": "ç‰¹", "2": "å„ª", "3": "è‰¯"}
    for rec in records:
        if not rec.strip(): continue
        try:
            m = re.search(r'(\d{8})\s+(\d{2})(S00\d{6})', rec)
            if not m: continue
            raw_date, level_code, market_anchor = m.group(1), m.group(2)[0], m.group(3)
            serial = rec[:m.start()].strip().replace(" ", "")
            market_name = MARKET_RULES.get(serial[:2], "å…¶ä»–")
            data_part = rec[m.end():]
            if '+' not in data_part: continue
            parts = data_part.split('+')
            pieces, weight = int(parts[0][-3:].strip()), int(parts[1].strip())
            price = int(parts[2].strip().split()[0][:-1]) if parts[2].strip() else 0
            total_val = int(parts[3].strip().split()[0]) if parts[3].strip() else 0
            buyer_match = re.search(r'^\d+', parts[-1].strip())
            buyer = buyer_match.group() if buyer_match else ""
            v_code_match = re.search(r'(F22|FP1|FP2|FP3|FP5|FI3)', parts[0])
            v_name = VARIETY_MAP.get(v_code_match.group(1), "èœœæ£—") if v_code_match else "èœœæ£—"
            dt_obj = datetime(int(raw_date[:3])+1911, int(raw_date[3:5]), int(raw_date[5:7])).date()
            farm = "å…¶ä»–"
            for name, code in FARMER_MAP.items():
                if code in market_anchor: farm = name; break
            if farm == "å…¶ä»–": continue
            rows.append({"è¾²æœƒ": farm, "æ—¥æœŸ": dt_obj, "å¸‚å ´": market_name, "å°ä»£": market_anchor[6:9], "ä»¶æ•¸": pieces, "å…¬æ–¤": weight, "å–®åƒ¹": price, "ç¸½åƒ¹": total_val, "è²·å®¶": buyer, "å“ç¨®": v_name})
        except: continue
    return rows

df = fetch_data()

# --- å´é‚Šæ¬„ï¼šåƒ…ä¿ç•™é–‹é—œ ---
st.sidebar.title("åŸºæœ¬è¨­å®š")
selected_markets = [m for m in MARKET_ORDER if st.sidebar.checkbox(f"é–‹å•Ÿ {m}", value=(m in ["ä¸€å¸‚", "äºŒå¸‚"]))]

# --- ä¸»ç•«é¢ ---
st.title("ğŸ è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº«")

if not df.empty:
    # ç¬¬ä¸€æ’ï¼šä¸‰å¤§ä¸»è¦é¸å–®
    r1, r2, r3 = st.columns(3)
    with r1:
        target_farm = st.selectbox("ğŸ¥ é¸æ“‡è¾²æœƒ", list(FARMER_MAP.keys()))
    with r2:
        target_v = st.selectbox("ğŸ é¸æ“‡å“ç¨®", df[df['è¾²æœƒ']==target_farm]['å“ç¨®'].unique())
    with r3:
        # --- é€™è£¡æ˜¯æ‚¨è¦çš„åŠŸèƒ½ï¼šæ”¹ç”¨ Selectbox ---
        target_sub = st.selectbox(
            "â­ å¸¸ç”¨å°ä»£ç¯©é¸",
            ["é¡¯ç¤ºå…¨éƒ¨", "633", "627", "626", "æ‰‹å‹•è¼¸å…¥"]
        )

    # ç¬¬äºŒæ’ï¼šé¡å¤–æœå°‹
    c1, c2, c3 = st.columns([1, 1, 1])
    with c1:
        max_date = df['æ—¥æœŸ'].max()
        date_range = st.date_input("ğŸ“… æ—¥æœŸå€é–“", value=[max_date, max_date])
    with c2:
        # å¦‚æœä¸Šé¢é¸äº†æ‰‹å‹•è¼¸å…¥ï¼Œé€™è£¡æ‰è®“ä½¿ç”¨è€…æ‰“å­—ï¼Œæˆ–è€…ä¸¦å­˜
        s_sub = st.text_input("ğŸ” æ‰‹å‹•è¼¸å…¥å°ä»£ (è‹¥ä¸Šæ–¹é¸é¡¯ç¤ºå…¨éƒ¨å‰‡ç„¡æ•ˆ)")
    with c3:
        s_buy = st.text_input("ğŸ‘¤ è²·å®¶æœå°‹")

    # --- éæ¿¾é‚è¼¯ ---
    f_df = df[(df['è¾²æœƒ'] == target_farm) & (df['å“ç¨®'] == target_v) & (df['å¸‚å ´'].isin(selected_markets))].copy()
    
    # å°ä»£éæ¿¾ï¼šSelectbox èˆ‡ Text_input è¯å‹•
    if target_sub != "é¡¯ç¤ºå…¨éƒ¨":
        if target_sub == "æ‰‹å‹•è¼¸å…¥":
            if s_sub: f_df = f_df[f_df['å°ä»£'].str.contains(s_sub)]
        else:
            f_df = f_df[f_df['å°ä»£'] == target_sub]

    if s_buy: f_df = f_df[f_df['è²·å®¶'].str.contains(s_buy)]
    
    # æ—¥æœŸèˆ‡è¡¨æ ¼é¡¯ç¤º (ç•¥)...
    st.dataframe(f_df, use_container_width=True, hide_index=True)
else:
    st.warning("âš ï¸ æ•¸æ“šåŠ è¼‰ä¸­æˆ–ç„¡è³‡æ–™ã€‚")