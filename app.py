import streamlit as st
import pandas as pd
import re
import requests
import concurrent.futures

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº«", layout="wide")

# è¾²æœƒå®šç¾© (åªä¿ç•™ç‡•å·¢ã€å¤§ç¤¾ã€é˜¿è“®)
FARMER_MAP = {"ç‡•å·¢": "S00076", "å¤§ç¤¾": "S00250", "é˜¿è“®": "S00098"}

try:
    GITHUB_TOKEN = st.secrets["github_token"]
except:
    st.error("âŒ è«‹è‡³ Streamlit å¾Œå° Secrets è¨­å®š github_token")
    st.stop()

def deep_parse(content):
    # æ ¸å¿ƒé›·é”ï¼šå°‹æ‰¾ [8ç¢¼æ—¥æœŸ][ç©ºæ ¼][2ç¢¼ç­‰ç´š]S00[å¸‚å ´+å°ä»£]
    pattern = re.compile(r'(\d{8})\s+(\d{2})(S00\d{6})')
    matches = list(pattern.finditer(content))
    rows = []
    grade_map = {"1": "ç‰¹", "2": "å„ª", "3": "è‰¯"}
    
    for i in range(len(matches)):
        try:
            m = matches[i]
            s_pos = m.start()   # æ—¥æœŸèµ·é»
            raw_date = m.group(1)
            level_code = m.group(2)[0] # 1, 2, 3
            anchor = m.group(3)        # S00250516
            
            # 1. æå–æµæ°´è™Ÿ (è™•ç†å¤§ç¤¾è¶…é•·ç©ºç™½)
            prev_end = matches[i-1].end() if i > 0 else 0
            # å¾€å‰æ‰¾ï¼Œé¿é–‹ä¸Šä¸€ç­†çš„æ•¸æ“šæ®µ (+è™Ÿå€)
            last_plus = content.rfind('+', prev_end, s_pos)
            search_from = last_plus + 35 if last_plus != -1 else prev_end
            serial = content[search_from:s_pos].strip().replace(" ", "").replace("\n", "").replace("\r", "")

            # 2. æ•¸æ“šæ®µè§£æ (å¾éŒ¨é»å¾Œå°‹æ‰¾ + è™Ÿä¸²)
            # ç¯„ä¾‹æ•¸æ“šï¼šS00250516 F22  003+00060+00220+000001320+ 000+8156
            data_area = content[m.end() : m.end() + 150]
            if '+' not in data_area: continue
            
            parts = data_area.split('+')
            
            # å“ç¨®ï¼šåœ¨ç¬¬ä¸€å€‹ + å‰é¢æœå°‹æœ‰æ•ˆå“ç¨®ä»£è™Ÿ
            variety_search = re.search(r'(F22|FP1|FP2|FP3|FP5|FI3)', parts[0])
            variety = variety_search.group(1) if variety_search else "F22"
            
            # æ•¸å€¼ç²¾ç¢ºæ ¡æº–
            pieces = int(parts[0][-3:].strip()) # ç¬¬ä¸€å€‹ + å‰ 3 ç¢¼
            weight = int(parts[1].strip())     # ç¬¬ä¸€å€‹èˆ‡ç¬¬äºŒå€‹ + ä¹‹é–“
            
            # å–®åƒ¹ä¿®æ­£ (00220 -> 220)
            p_raw = parts[2].strip().split()[0]
            price = int(p_raw[:-1]) if p_raw else 0
            
            # ç¸½åƒ¹ä¿®æ­£ (0000013200 -> 13200)
            t_raw = parts[3].strip().split()[0]
            total = int(t_raw[:-1]) if t_raw else 0
            
            # è²·å®¶ï¼šæœ€å¾Œä¸€æ®µ
            buyer = parts[-1].strip()[:4]

            # 3. åˆ¤å®šè¾²æœƒ
            farm = "å…¶ä»–"
            for name, code in FARMER_MAP.items():
                if code in anchor:
                    farm = name
                    break
            if farm == "å…¶ä»–": continue

            rows.append({
                "è¾²æœƒ": farm, "æ—¥æœŸ": f"{raw_date[:3]}/{raw_date[3:5]}/{raw_date[5:7]}",
                "ç­‰ç´š": grade_map.get(level_code, level_code), "å°ä»£": anchor[6:9],
                "ä»¶æ•¸": pieces, "å…¬æ–¤": weight, "å–®åƒ¹": price, "ç¸½åƒ¹": total,
                "è²·å®¶": buyer, "æµæ°´è™Ÿ": serial, "å“ç¨®": variety, "raw_date": raw_date[:7]
            })
        except: continue
    return rows

@st.cache_data(ttl=60)
def fetch_data():
    all_rows = []
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    try:
        r = requests.get("https://api.github.com/repos/goodgorilla5/chaochao-catcher/contents/", headers=headers)
        files = [f for f in r.json() if f['name'].lower().endswith('.scp')]
        for f_info in files:
            res = requests.get(f_info['download_url'], headers=headers)
            all_rows.extend(deep_parse(res.content.decode("big5", errors="ignore")))
        df = pd.DataFrame(all_rows)
        if not df.empty:
            df = df.drop_duplicates(subset=["æµæ°´è™Ÿ", "å°ä»£", "å–®åƒ¹"])
            return df.sort_values(["raw_date", "å–®åƒ¹"], ascending=[False, False])
    except: pass
    return pd.DataFrame()

# --- ä¸»ä»‹é¢ ---
st.title("ğŸ è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº«")
df = fetch_data()

if not df.empty:
    st.sidebar.header("ğŸ¨ é¡¯ç¤ºè¨­å®š")
    show_serial = st.sidebar.checkbox("é¡¯ç¤ºæµæ°´è™Ÿ", value=False)
    show_total = st.sidebar.checkbox("é¡¯ç¤ºç¸½åƒ¹", value=False)

    target_farm = st.selectbox("ğŸ¥ é¸æ“‡è¾²æœƒ", list(FARMER_MAP.keys()))
    f_df = df[df['è¾²æœƒ'] == target_farm].copy()
    
    v_list = sorted(f_df['å“ç¨®'].unique())
    target_v = st.selectbox("ğŸ é¸æ“‡å“ç¨®", v_list, index=v_list.index("F22") if "F22" in v_list else 0)
    f_df = f_df[f_df['å“ç¨®'] == target_v]

    dates = sorted(f_df['raw_date'].unique(), reverse=True)
    sel_date = st.selectbox("ğŸ“… é¸æ“‡æ—¥æœŸ", dates)
    
    sc1, sc2 = st.columns(2)
    with sc1: s_sub = st.text_input("ğŸ” æœå°‹å°ä»£")
    with sc2: s_buy = st.text_input("ğŸ‘¤ æœå°‹è²·å®¶")

    final_df = f_df[f_df['raw_date'] == sel_date]
    if s_sub: final_df = final_df[final_df['å°ä»£'].str.contains(s_sub)]
    if s_buy: final_df = final_df[final_df['è²·å®¶'].str.contains(s_buy)]

    cols = ["æ—¥æœŸ", "ç­‰ç´š", "å°ä»£", "ä»¶æ•¸", "å…¬æ–¤", "å–®åƒ¹", "è²·å®¶"]
    if show_serial: cols.insert(0, "æµæ°´è™Ÿ")
    if show_total: cols.insert(cols.index("å–®åƒ¹")+1, "ç¸½åƒ¹")
    
    st.dataframe(final_df[cols], use_container_width=True, height=450, hide_index=True)

    # --- çµ±è¨ˆè³‡è¨Šå€ (å›æ­¸æ‚¨æœ€å–œæ­¡çš„å¡ç‰‡æ¨£å¼) ---
    st.divider()
    if not final_df.empty:
        t_pcs, t_kg, t_val = final_df['ä»¶æ•¸'].sum(), final_df['å…¬æ–¤'].sum(), final_df['ç¸½åƒ¹'].sum()
        avg_p = t_val / t_kg if t_kg > 0 else 0
        st.markdown(f"##### ğŸ“‰ {target_farm} - {target_v} æ•¸æ“šæ‘˜è¦")
        m_cols = st.columns(6)
        metrics = [
            ("ç¸½ä»¶æ•¸", f"{int(t_pcs)} ä»¶"), ("ç¸½å…¬æ–¤", f"{int(t_kg)} kg"),
            ("æœ€é«˜åƒ¹", f"{final_df['å–®åƒ¹'].max()} å…ƒ"), ("æœ€ä½åƒ¹", f"{final_df['å–®åƒ¹'].min()} å…ƒ"),
            ("å¹³å‡å–®åƒ¹", f"{avg_p:.1f} å…ƒ"), ("å€é–“ç¸½åƒ¹", f"{int(t_val):,} å…ƒ")
        ]
        for i, (l, v) in enumerate(metrics):
            with m_cols[i]:
                st.markdown(f'<div style="background-color:#f0f2f6;padding:10px;border-radius:5px;text-align:center;">'
                            f'<p style="margin:0;font-size:12px;color:#555;">{l}</p>'
                            f'<p style="margin:0;font-size:16px;font-weight:bold;color:#111;">{v}</p></div>', unsafe_allow_html=True)
else:
    st.warning("ğŸ˜­ å€‰åº«ä¸­ç„¡æœ‰æ•ˆè³‡æ–™ã€‚")