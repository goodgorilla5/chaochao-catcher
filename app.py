import streamlit as st
import pandas as pd
import re
import requests
import concurrent.futures

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº«", layout="wide")

# è¾²æœƒå°ç…§
FARMER_MAP = {"ç‡•å·¢": "S00076", "å¤§ç¤¾": "S00250", "é˜¿è“®": "S00098"}

try:
    GITHUB_TOKEN = st.secrets["github_token"]
except:
    st.error("âŒ è«‹è‡³ Streamlit å¾Œå° Secrets è¨­å®š github_token")
    st.stop()

def parse_farmer_data(content):
    # æ”¹ç”¨æ›´å¯¬é¬†çš„åˆ‡å‰²ï¼šåªè¦æ˜¯é€£çºŒç©ºæ ¼ (2å€‹ä»¥ä¸Š) æˆ–æ›è¡Œå°±åˆ‡é–‹
    chunks = re.split(r'\s{2,}|\n', content)
    rows = []
    grade_map = {"1": "ç‰¹", "2": "å„ª", "3": "è‰¯"}
    
    for chunk in chunks:
        chunk = chunk.strip()
        # åªè¦åŒ…å« F22 (èœœæ£—) ä¸”åŒ…å« S00 å¸‚å ´æ¨™è¨˜
        if "F22" in chunk and "S00" in chunk and "+" in chunk:
            try:
                # 1. å®šä½ S00 éŒ¨é»
                s_idx = chunk.find("S00")
                if s_idx < 10: continue

                # 2. æ ¹æ“šæ‚¨çš„æ³•å‰‡ï¼šS00 å¾€å‰æ¨ 10 ç¢¼æ˜¯æ—¥æœŸèˆ‡ç­‰ç´š
                # ä½ç½®ï¼š[æµæ°´è™Ÿ...][æ—¥æœŸ8ç¢¼][ç­‰ç´š2ç¢¼][S00...]
                # ç­‰ç´šå°±åœ¨ S00 çš„å‰ 2 ç¢¼
                level_code = chunk[s_idx-2] # å–å¾— 1, 2 æˆ– 3
                level = grade_map.get(level_code, level_code)

                # æ—¥æœŸå°±åœ¨ç­‰ç´šçš„å‰ 8 ç¢¼ (11502111)
                date_str_raw = chunk[s_idx-10 : s_idx-2].strip()
                display_date = f"{date_str_raw[:3]}/{date_str_raw[3:5]}/{date_str_raw[5:7]}"
                date_for_obj = date_str_raw[:7]

                # æµæ°´è™Ÿå°±æ˜¯æ—¥æœŸä¹‹å‰çš„æ‰€æœ‰å­—å…ƒï¼Œç›´æ¥å»ç©ºæ ¼
                serial = chunk[:s_idx-10].strip().replace(" ", "")

                # 3. åˆ¤å®šè¾²æœƒ
                farm_name = "å…¶ä»–"
                for name, code in FARMER_MAP.items():
                    if code in chunk:
                        farm_name = name
                        break
                
                # 4. æå–å°ä»£ (S00XXX ä¹‹å¾Œçš„ 3 ç¢¼)
                sub_id = chunk[s_idx+6 : s_idx+9].strip()

                # 5. æå–æ•¸æ“šæ®µ (+ è™Ÿé€£æ¥çš„éƒ¨åˆ†)
                parts = chunk.split('+')
                pieces = int(parts[0][-3:].strip() or 0)
                weight = int(parts[1].strip() or 0)
                # å–®åƒ¹å»æ‰æœ€å¾Œä¸€ç¢¼ 0
                p_raw = parts[2].strip().split(' ')[0]
                price = int(p_raw[:-1] if p_raw else 0)
                total_val = int(parts[3].strip() or 0)
                buyer = parts[-1].strip()[:4]

                rows.append({
                    "è¾²æœƒ": farm_name, "æ—¥æœŸç·¨ç¢¼": date_for_obj, "é¡¯ç¤ºæ—¥æœŸ": display_date,
                    "æµæ°´è™Ÿ": serial, "ç­‰ç´š": level, "å°ä»£": sub_id,
                    "ä»¶æ•¸": pieces, "å…¬æ–¤": weight, "å–®åƒ¹": price, "ç¸½åƒ¹": total_val, "è²·å®¶": buyer
                })
            except: continue
    return rows

@st.cache_data(ttl=60)
def fetch_data():
    all_rows = []
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    REPO = "goodgorilla5/chaochao-catcher"
    try:
        r = requests.get(f"https://api.github.com/repos/{REPO}/contents/", headers=headers)
        files = [f for f in r.json() if f['name'].lower().endswith('.scp')]
        
        def process_file(file_info):
            res = requests.get(file_info['download_url'], headers=headers)
            return parse_farmer_data(res.content.decode("big5", errors="ignore"))

        with concurrent.futures.ThreadPoolExecutor() as exe:
            results = list(exe.map(process_file, files))
        for res in results: all_rows.extend(res)
        
        df = pd.DataFrame(all_rows)
        if not df.empty:
            df = df.drop_duplicates(subset=["æµæ°´è™Ÿ", "å°ä»£", "å–®åƒ¹"])
            df['date_obj'] = pd.to_datetime(df['æ—¥æœŸç·¨ç¢¼'].apply(lambda x: str(int(x[:3])+1911)+x[3:]), format='%Y%m%d')
            return df.sort_values("å–®åƒ¹", ascending=False)
    except: pass
    return pd.DataFrame()

# --- ä¸»ä»‹é¢ ---
st.title("ğŸ è¾²æœƒèœœæ£—è¡Œæƒ…å¤§æ•¸æ“šåº«")
df = fetch_data()

if not df.empty:
    farm = st.selectbox("ğŸ¥ é¸æ“‡è¾²æœƒ", options=["ç‡•å·¢", "å¤§ç¤¾", "é˜¿è“®"])
    
    # ç¯©é¸
    f_df = df[df['è¾²æœƒ'] == farm].copy()
    
    # æ—¥æœŸé¸æ“‡
    dates = sorted(f_df['date_obj'].dt.date.unique(), reverse=True)
    target_date = st.selectbox("ğŸ“… é¸æ“‡æ—¥æœŸ", options=dates)
    f_df = f_df[f_df['date_obj'].dt.date == target_date]

    st.dataframe(f_df[["é¡¯ç¤ºæ—¥æœŸ", "å°ä»£", "ä»¶æ•¸", "å…¬æ–¤", "å–®åƒ¹", "è²·å®¶"]].rename(columns={"é¡¯ç¤ºæ—¥æœŸ":"æ—¥æœŸ"}), 
                 use_container_width=True, hide_index=True)

    # çµ±è¨ˆ
    st.divider()
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ç¸½ä»¶æ•¸", f"{int(f_df['ä»¶æ•¸'].sum())}")
    c2.metric("ç¸½å…¬æ–¤", f"{int(f_df['å…¬æ–¤'].sum())}")
    c3.metric("æœ€é«˜åƒ¹", f"{f_df['å–®åƒ¹'].max()}")
    c4.metric("å¹³å‡åƒ¹", f"{f_df['ç¸½åƒ¹'].sum()/f_df['å…¬æ–¤'].sum():.1f}" if f_df['å…¬æ–¤'].sum()>0 else 0)
else:
    st.warning("ğŸ˜­ æ‰¾ä¸åˆ°è³‡æ–™ï¼Œè«‹ç¢ºèª GitHub å€‰åº«å…§æœ‰ SCP æª”æ¡ˆã€‚")