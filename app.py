import streamlit as st
import pandas as pd
import re
import requests
from datetime import datetime

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº«", layout="wide")

# å›ºå®šå®šç¾©
FARMER_MAP = {"ç‡•å·¢": "S00076", "å¤§ç¤¾": "S00250", "é˜¿è“®": "S00098"}
MARKET_RULES = {"A1": "ä¸€å¸‚", "A2": "äºŒå¸‚", "F1": "ä¸‰é‡", "F2": "æ¿æ©‹", "T1": "å°ä¸­", "K1": "é«˜é›„"}
MARKET_ORDER = ["ä¸€å¸‚", "äºŒå¸‚", "ä¸‰é‡", "æ¿æ©‹", "å°ä¸­", "é«˜é›„"]
VARIETY_MAP = {"F22": "èœœæ£—", "FP1": "çç èŠ­", "FP2": "ç´…å¿ƒ", "FP3": "å¸ç‹èŠ­", "FP5": "æ°´æ™¶ç„¡ç±½", "FI3": "å…¶ä»–"}
SORTED_V_NAMES = ["èœœæ£—", "çç èŠ­", "ç´…å¿ƒ", "å¸ç‹èŠ­", "æ°´æ™¶ç„¡ç±½"]

try:
    GITHUB_TOKEN = st.secrets["github_token"]
except:
    st.error("âŒ è«‹åœ¨ Streamlit Cloud è¨­å®šä¸­é…ç½® github_token")
    st.stop()

def deep_parse(content):
    records = re.split(r'(?=[ATKF]\d{10,})', content) 
    rows = []
    grade_map = {"1": "ç‰¹", "2": "å„ª", "3": "è‰¯"}
    for rec in records:
        if not rec.strip(): continue
        try:
            m = re.search(r'(\d{8})\s+(\d{2})(S00\d{6})', rec)
            if not m: continue
            raw_date, level_code, market_anchor = m.group(1), m.group(2)[0], m.group(3)
            serial = rec[:m.start()].strip().replace(" ", "")
            market_name = MARKET_RULES.get(serial[:2], "å…¶ä»–")
            data_part = rec[m.end():]
            if '+' not in data_part: continue
            parts = data_part.split('+')
            pieces, weight = int(parts[0][-3:].strip()), int(parts[1].strip())
            price = int(parts[2].strip().split()[0][:-1]) if parts[2].strip() else 0
            total_val = int(parts[3].strip().split()[0]) if parts[3].strip() else 0
            buyer_match = re.search(r'^\d+', parts[-1].strip())
            buyer = buyer_match.group() if buyer_match else ""
            v_code_match = re.search(r'(F22|FP1|FP2|FP3|FP5|FI3)', parts[0])
            v_name = VARIETY_MAP.get(v_code_match.group(1), "èœœæ£—") if v_code_match else "èœœæ£—"
            dt_obj = datetime(int(raw_date[:3])+1911, int(raw_date[3:5]), int(raw_date[5:7])).date()
            farm = "å…¶ä»–"
            for name, code in FARMER_MAP.items():
                if code in market_anchor: farm = name; break
            if farm == "å…¶ä»–": continue
            rows.append({"è¾²æœƒ": farm, "æ—¥æœŸ": dt_obj, "é¡¯ç¤ºæ—¥æœŸ": f"{raw_date[:3]}/{raw_date[3:5]}/{raw_date[5:7]}", "å¸‚å ´": market_name, "ç­‰ç´š": grade_map.get(level_code, level_code), "å°ä»£": market_anchor[6:9], "ä»¶æ•¸": pieces, "å…¬æ–¤": weight, "å–®åƒ¹": price, "ç¸½åƒ¹": total_val, "è²·å®¶": buyer, "æµæ°´è™Ÿ": serial, "å“ç¨®": v_name})
        except: continue
    return rows

@st.cache_data(ttl=60)
def fetch_data():
    all_rows = []
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    try:
        r = requests.get(f"https://api.github.com/repos/goodgorilla5/chaochao-catcher/contents/", headers=headers)
        files = [f for f in r.json() if f['name'].lower().endswith('.scp')]
        for f_info in files:
            res = requests.get(f_info['download_url'], headers=headers)
            all_rows.extend(deep_parse(res.content.decode("big5", errors="ignore")))
        full_df = pd.DataFrame(all_rows)
        return full_df.drop_duplicates(subset=["æµæ°´è™Ÿ", "æ—¥æœŸ", "å°ä»£", "ä»¶æ•¸", "ç¸½åƒ¹"]) if not full_df.empty else full_df
    except: return pd.DataFrame()

df = fetch_data()

# --- å´é‚Šæ¬„ (å„ªåŒ–æ’ç‰ˆ) ---
st.sidebar.title("âš™ï¸ æ§åˆ¶é¢æ¿")

# 1. å¸‚å ´ç¯©é¸
st.sidebar.subheader("ğŸ¢ å¸‚å ´é¸æ“‡")
all_market_selected = st.sidebar.checkbox("å…¨é¸æ‰€æœ‰å¸‚å ´", value=False)
selected_markets = []
for m in MARKET_ORDER:
    # å¦‚æœé»é¸å…¨é¸ï¼Œå‰‡æ‰€æœ‰ checkbox å¼·åˆ¶ç‚º True
    val = True if all_market_selected else (m in ["ä¸€å¸‚", "äºŒå¸‚"])
    if st.sidebar.checkbox(m, value=val, key=f"mkt_{m}"):
        selected_markets.append(m)

st.sidebar.markdown("---") # åˆ†éš”ç·š

# 2. é¡¯ç¤ºè¨­å®š
st.sidebar.subheader("ğŸ‘ï¸ é¡¯ç¤ºæ¬„ä½")
show_serial = st.sidebar.checkbox("é¡¯ç¤ºæµæ°´è™Ÿ", value=True) # é è¨­é–‹å•Ÿ
show_grade = st.sidebar.checkbox("é¡¯ç¤ºç­‰ç´š", value=False)
show_total = st.sidebar.checkbox("é¡¯ç¤ºç¸½åƒ¹", value=False)

# --- ä¸»ç•«é¢ ---
st.title("ğŸ è¾²æœƒè¡Œæƒ…å¤§æ•¸æ“šåº«")

if not df.empty:
    c1, c2, c3 = st.columns(3)
    with c1: target_farm = st.selectbox("ğŸ¥ é¸æ“‡è¾²æœƒ", list(FARMER_MAP.keys()))
    with c2: 
        v_list = df[df['è¾²æœƒ']==target_farm]['å“ç¨®'].unique()
        target_v = st.selectbox("ğŸ é¸æ“‡å“ç¨®", [v for v in SORTED_V_NAMES if v in v_list] if v_list.any() else v_list)
    with c3: 
        # è£œå›æ‰€æœ‰æ’åºé¸é …
        sort_opt = st.selectbox("ğŸ”ƒ æ’åºæ–¹å¼", ["åƒ¹æ ¼ï¼šç”±é«˜è‡³ä½", "åƒ¹æ ¼ï¼šç”±ä½è‡³é«˜", "æ—¥æœŸï¼šç”±æ–°åˆ°èˆŠ", "æ—¥æœŸï¼šç”±èˆŠè‡³æ–°"])

    st.markdown("---")
    st.markdown("##### â­ å¸¸ç”¨å°ä»£å¿«é¸")
    fc1, fc2, fc3, fc4 = st.columns([1, 1, 1, 3])
    fav_subs = []
    with fc1: 
        if st.checkbox("633", key="f633"): fav_subs.append("633")
    with fc2: 
        if st.checkbox("627", key="f627"): fav_subs.append("627")
    with fc3: 
        if st.checkbox("626", key="f626"): fav_subs.append("626")
    with fc4: s_sub = st.text_input("ğŸ” æ‰‹å‹•è¼¸å…¥å°ä»£")

    c_d1, c_d2 = st.columns(2)
    with c_d1:
        max_dt = df['æ—¥æœŸ'].max()
        date_range = st.date_input("ğŸ“… æ—¥æœŸå€é–“", value=[max_dt, max_dt])
    with c_d2: s_buy = st.text_input("ğŸ‘¤ è²·å®¶æœå°‹")

    # éæ¿¾é‚è¼¯
    f_df = df[(df['è¾²æœƒ']==target_farm) & (df['å“ç¨®']==target_v) & (df['å¸‚å ´'].isin(selected_markets))].copy()
    if isinstance(date_range, (list, tuple)) and len(date_range) == 2:
        f_df = f_df[(f_df['æ—¥æœŸ'] >= date_range[0]) & (f_df['æ—¥æœŸ'] <= date_range[1])]
    
    # å°ä»£é‚è¼¯ (å·²ä¿®æ­£æ‹¼å­—)
    if fav_subs or s_sub:
        if fav_subs and not s_sub: f_df = f_df[f_df['å°ä»£'].isin(fav_subs)]
        elif s_sub and not fav_subs: f_df = f_df[f_df['å°ä»£'].str.contains(s_sub)]
        else: f_df = f_df[f_df['å°ä»£'].isin(fav_subs) | f_df['å°ä»£'].str.contains(s_sub)]
    
    if s_buy: f_df = f_df[f_df['è²·å®¶'].str.contains(s_buy)]

    # æ’åºé‚è¼¯ä¿®æ­£
    if sort_opt == "åƒ¹æ ¼ï¼šç”±é«˜è‡³ä½":
        f_df = f_df.sort_values("å–®åƒ¹", ascending=False)
    elif sort_opt == "åƒ¹æ ¼ï¼šç”±ä½è‡³é«˜":
        f_df = f_df.sort_values("å–®åƒ¹", ascending=True)
    elif sort_opt == "æ—¥æœŸï¼šç”±æ–°åˆ°èˆŠ":
        f_df = f_df.sort_values(["æ—¥æœŸ", "å–®åƒ¹"], ascending=[False, False])
    elif sort_opt == "æ—¥æœŸï¼šç”±èˆŠè‡³æ–°":
        f_df = f_df.sort_values(["æ—¥æœŸ", "å–®åƒ¹"], ascending=[True, False])

    # æ¬„ä½é¡¯ç¤ºè™•ç†
    disp_cols = ["é¡¯ç¤ºæ—¥æœŸ", "å¸‚å ´", "å°ä»£", "ä»¶æ•¸", "å…¬æ–¤", "å–®åƒ¹", "è²·å®¶"]
    if show_grade: disp_cols.insert(2, "ç­‰ç´š")
    if show_total: disp_cols.append("ç¸½åƒ¹")
    if show_serial: disp_cols.insert(0, "æµæ°´è™Ÿ")
    
    st.dataframe(f_df[disp_cols].rename(columns={"é¡¯ç¤ºæ—¥æœŸ":"æ—¥æœŸ"}), use_container_width=True, height=400, hide_index=True)

    # --- ğŸ“Š å€é–“è¡Œæƒ…å½™ç¸½ ---
    if not f_df.empty:
        st.divider()
        t_pcs, t_kg, t_val = int(f_df['ä»¶æ•¸'].sum()), int(f_df['å…¬æ–¤'].sum()), int(f_df['ç¸½åƒ¹'].sum())
        avg_p, max_p, min_p = t_val/t_kg if t_kg>0 else 0, f_df['å–®åƒ¹'].max(), f_df['å–®åƒ¹'].min()
        
        st.markdown("### ğŸ“ˆ å€é–“è¡Œæƒ…å½™ç¸½")
        m1, m2, m3 = st.columns(3)
        with m1:
            st.markdown(f"**æœ€é«˜åƒ¹**ï¼š<span style='font-size:20px; color:#ff4b4b;'>{max_p}</span> å…ƒ", unsafe_allow_html=True)
            st.markdown(f"**æœ€ä½åƒ¹**ï¼š<span style='font-size:20px; color:#1f77b4;'>{min_p}</span> å…ƒ", unsafe_allow_html=True)
        with m2:
            st.markdown(f"**å¹³å‡å–®åƒ¹**ï¼š<span style='font-size:20px;'>{avg_p:.1f}</span> å…ƒ", unsafe_allow_html=True)
            st.markdown(f"**å€é–“ç¸½åƒ¹**ï¼š<span style='font-size:20px;'>{t_val:,}</span> å…ƒ", unsafe_allow_html=True)
        with m3:
            st.markdown(f"**ç¸½ä»¶æ•¸**ï¼š<span style='font-size:20px;'>{t_pcs}</span> ä»¶", unsafe_allow_html=True)
            st.markdown(f"**ç¸½å…¬æ–¤**ï¼š<span style='font-size:20px;'>{t_kg}</span> kg", unsafe_allow_html=True)
else:
    st.warning("âš ï¸ æ•¸æ“šåŠ è¼‰ä¸­æˆ–ç„¡è³‡æ–™ã€‚")